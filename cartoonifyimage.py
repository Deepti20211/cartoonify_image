# -*- coding: utf-8 -*-
"""cartoonifyimage.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ghaUMsJNEgnx9uZh8lj0T8T9EaC_WElX
"""

import cv2
import numpy as np
import matplotlib.pyplot as plt
from google.colab.patches import cv2_imshow

def read_file(filename):
    img = cv2.imread(filename)
    img = cv2.cvtColor(img , cv2.COLOR_BGR2RGB)
    plt.imshow(img)
    plt.show()
    return img

filename = "cri.jpg"
read_file(filename)

def edge_mask(img , line_size, blur_value):
    grey = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)
    grey_blur = cv2.medianBlur(grey,blur_value)
    edges=cv2.adaptiveThreshold(grey_blur,255,cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size , blur_value)
    return edges

img=read_file(filename)
line_size, blur_value = 5,7
edges = edge_mask(img , line_size, blur_value)
plt.imshow(edges , cmap = "binary")
plt.show()

# reduce the color palette
def color_quantization(img , k):

 # transform the image
 data = np.float32(img).reshape((-1,3))
 # determine criteria
 criteria = (cv2.TERM_CRITERIA_EPS+ cv2.TERM_CRITERIA_MAX_ITER,20,0.001)

 ## Imlementing k-means

 ret, label, center = cv2.kmeans(data, k, 0, criteria , 10, cv2.KMEANS_RANDOM_CENTERS) 
 center = np.uint8(center)

 result = center[label.flatten()]
 result = result.reshape(img.shape)

 return result

img = color_quantization(img , k=8)
plt.imshow(img)
plt.show()

# reduce the noise
diameter = 3
sigmaColor = 200
sigmaSpace = 200
blurred = cv2.bilateralFilter(img, diameter, sigmaColor, sigmaSpace)



plt.imshow(blurred)
plt.show()

def cartoon(blurred):
  c=cv2.bitwise_and(blurred , blurred , mask= edges)

  plt.imshow(c)
  plt.show()

cartoon(blurred)